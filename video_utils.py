
import os
import random
import numpy as np
from PIL import Image, ImageFilter, ImageDraw, ImageFont, ImageOps
from moviepy.editor import (
    ImageClip, CompositeVideoClip, ColorClip, VideoClip, AudioFileClip,
    vfx, transfx, concatenate_videoclips
)
from moviepy.video.fx.all import crop, resize
# Try import audio_loop
try:
    from moviepy.audio.fx.all import audio_loop
except ImportError:
    # Fallback for older moviepy
    audio_loop = None

DEFAULT_FONT = "arial.ttf" # Windows standard
ASSETS_DIR = "assets"

# Monkey-patch: Fix MoviePy compatibility with Pillow 10+
if not hasattr(Image, 'ANTIALIAS'):
    Image.ANTIALIAS = Image.LANCZOS

# ============================================================
# ğŸ“ Aspect Ratio & Layout
# ============================================================

def resize_with_blur(clip, target_size=(1080, 1920)):
    """
    ç”»åƒãŒ9:16ã§ãªã„å ´åˆã€èƒŒæ™¯ã«ãƒ–ãƒ©ãƒ¼ç”»åƒã‚’é…ç½®ã—ã¦ä½™ç™½ã‚’åŸ‹ã‚ã‚‹
    """
    w, h = clip.size
    target_w, target_h = target_size
    
    # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”è¨ˆç®—
    img_ratio = w / h
    target_ratio = target_w / target_h
    
    # ã»ã¼ä¸€è‡´ãªã‚‰ãƒªã‚µã‚¤ã‚ºã—ã¦ã‚¯ãƒ­ãƒƒãƒ—
    if abs(img_ratio - target_ratio) < 0.05:
        if img_ratio > target_ratio:
            return clip.resize(height=target_h).crop(x1=(clip.w*target_h/clip.h - target_w)/2, width=target_w, height=target_h)
        else:
            return clip.resize(width=target_w).crop(y1=(clip.h*target_w/clip.w - target_h)/2, width=target_w, height=target_h)

    # ç¸¦é•·ã™ãã‚‹ or æ¨ªé•·ã™ãã‚‹å ´åˆ
    if img_ratio > target_ratio:
        # æ¨ªé•·: å¹…ã‚’åˆã‚ã›ã¦ä¸Šä¸‹ã«é»’å¸¯(ãƒ–ãƒ©ãƒ¼)
        main = clip.resize(width=target_w)
    else:
        # ç¸¦é•·: é«˜ã•ã‚’åˆã‚ã›ã¦å·¦å³ã«é»’å¸¯(ãƒ–ãƒ©ãƒ¼)
        main = clip.resize(height=target_h)
        
    # èƒŒæ™¯: ç”»é¢ã„ã£ã±ã„ã«æ‹¡å¤§ã—ã¦ãƒ–ãƒ©ãƒ¼ (ç°¡æ˜“çš„ã«æš—ãã™ã‚‹)
    bg = clip.resize(height=target_h if img_ratio > target_ratio else target_w * 2)
    bg = bg.crop(x_center=bg.w/2, y_center=bg.h/2, width=target_w, height=target_h)
    bg = bg.fx(vfx.colorx, 0.4) # æš—ãã™ã‚‹
    
    return CompositeVideoClip([bg.set_position("center"), main.set_position("center")], size=target_size)

# ============================================================
# ğŸ¬ Animations
# ============================================================

def apply_animation(clip, animation_type, duration):
    """
    config.py ã§å®šç¾©ã•ã‚ŒãŸã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’é©ç”¨
    """
    clip = clip.set_duration(duration)
    w, h = clip.size
    
    if animation_type == "zoom_in_crossfade":
        return clip.resize(lambda t: 1 + 0.05 * t)
        
    elif animation_type == "zoom_center_impact":
        return clip.resize(lambda t: 1 + 0.3 * t)
        
    elif animation_type == "slide_in_left":
        return clip.set_position(lambda t: (min(0, int(w * (t/0.5 - 1))), "center") if t < 0.5 else "center")
        
    elif animation_type == "slide_in_vertical":
        return clip.set_position(lambda t: ("center", min(0, int(h * (t/0.5 - 1)))) if t < 0.5 else "center")
    
    elif animation_type == "pan_horizontal":
        clip = clip.resize(1.2)
        return clip.set_position(lambda t: (int(-0.1*w + 0.05*w*t), "center"))
        
    elif animation_type == "soft_pan":
        clip = clip.resize(1.1)
        return clip.set_position(lambda t: ("center", int(-0.05*h + 0.02*h*t)))
        
    elif animation_type == "flash_cut":
        return clip.fx(vfx.fadein, 0.1)
        
    elif animation_type == "pulse_zoom":
        return clip.resize(lambda t: 1 + 0.05 * abs(np.sin(t * 3)))
        
    elif animation_type == "bounce_zoom":
        return clip.resize(lambda t: 1 + 0.1 * abs(np.sin(t * 5)))

    # Default
    return clip

# ============================================================
# ğŸ’§ Watermark
# ============================================================

def add_watermark(video_clip, logo_path="assets/logo.png", opacity=0.3):
    if not os.path.exists(logo_path):
        return video_clip
        
    logo = ImageClip(logo_path).resize(width=video_clip.w * 0.15) 
    logo = logo.set_opacity(opacity)
    # å³ä¸‹ (ãƒãƒ¼ã‚¸ãƒ³20px)
    logo = logo.set_position(("right", "bottom")).set_duration(video_clip.duration).margin(right=20, bottom=20, opacity=0)
    
    return CompositeVideoClip([video_clip, logo], size=video_clip.size)

# ============================================================
# ğŸ“ Text Overlay (via PIL)
# ============================================================

def create_text_image(text, font_path, fontsize=60, color='white', bg_color=None, size=(1080, 400)):
    """
    PILã‚’ä½¿ã£ã¦ãƒ†ã‚­ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆã—ã€ImageClipã¨ã—ã¦è¿”ã™
    """
    if not text:
        return None
        
    # ã‚­ãƒ£ãƒ³ãƒã‚¹ä½œæˆ (é€æ˜)
    img = Image.new('RGBA', size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    # ãƒ•ã‚©ãƒ³ãƒˆèª­ã¿è¾¼ã¿
    try:
        font = ImageFont.truetype(font_path, fontsize)
    except OSError:
        font = ImageFont.load_default()
    
    # ä¸­å¤®é…ç½®è¨ˆç®—
    try:
        bbox = draw.textbbox((0, 0), text, font=font)
        text_w = bbox[2] - bbox[0]
        text_h = bbox[3] - bbox[1]
    except:
        # Fallback for old PIL
        text_w, text_h = draw.textsize(text, font=font)
    
    x = (size[0] - text_w) / 2
    y = (size[1] - text_h) / 2
    
    # èƒŒæ™¯çŸ©å½¢
    if bg_color:
        padding = 20
        draw.rectangle(
            [x - padding, y - padding, x + text_w + padding, y + text_h + padding],
            fill=bg_color
        )
    
    # æ–‡å­—æç”»
    # è¦–èªæ€§å‘ä¸Šã®ãŸã‚ã€ç¸å–ã‚Šï¼ˆã‚¹ãƒˆãƒ­ãƒ¼ã‚¯ï¼‰ã‚’ä»˜ã‘ã‚‹
    # è‰²ã«ã‚ˆã£ã¦ã‚¹ãƒˆãƒ­ãƒ¼ã‚¯è‰²ã‚’å¤‰ãˆã‚‹
    stroke_color = 'black'
    if color.lower() in ['black', '#000000', '#000'] or (color.startswith('#') and color.lower() < '#444'):
        stroke_color = 'white'
        
    # æ–‡å­—æç”» (stroke_widthãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯PIL 4.2+ã§åˆ©ç”¨å¯èƒ½)
    try:
        draw.text((x, y), text, font=font, fill=color, stroke_width=4, stroke_fill=stroke_color)
    except:
        # å¤ã„PILã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ (ç°¡æ˜“å½±)
        shadow_off = 3
        draw.text((x+shadow_off, y+shadow_off), text, font=font, fill=stroke_color)
        draw.text((x, y), text, font=font, fill=color)
    
    return np.array(img)

def create_text_clip_pil(text, font_path, fontsize=70, color='white', bg_color=None, duration=3, canvas_size=(1080, 1920)):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒƒãƒ—ç”Ÿæˆ (è§£åƒåº¦å¯¾å¿œ)
    """
    # è§£åƒåº¦ã«åˆã‚ã›ã¦ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã¨ã‚¨ãƒªã‚¢ã‚’èª¿æ•´
    scale = canvas_size[0] / 1080.0
    scaled_fontsize = int(fontsize * scale)
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢: å¹…ã¯ç”»é¢ã„ã£ã±ã„ã€é«˜ã•ã¯30%
    area_w = canvas_size[0]
    area_h = int(canvas_size[1] * 0.3)
    
    img_array = create_text_image(text, font_path, scaled_fontsize, color, bg_color, size=(area_w, area_h))
    if img_array is None:
        return None
        
    txt_clip = ImageClip(img_array).set_duration(duration)
    
    # ä½ç½®: ç”»é¢ä¸‹éƒ¨ (marginèª¿æ•´)
    bottom_margin = int(canvas_size[1] * 0.15)
    txt_clip = txt_clip.set_position(("center", "bottom")).margin(bottom=bottom_margin, opacity=0)
    
    return txt_clip

# ============================================================
# ğŸš€ Generator Main
# ============================================================

def generate_reel(images, texts, preset, output_path="output/reel.mp4", logo_path="assets/logo.png", target_resolution=(1080, 1920)):
    """
    ãƒ¡ã‚¤ãƒ³ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
    """
    clips = []
    
    for i, img_path in enumerate(images):
        txt = texts[i] if i < len(texts) else ""
        
        # 1. ç”»åƒèª­ã¿è¾¼ã¿ & EXIFå›è»¢
        pil_img = Image.open(img_path)
        pil_img = ImageOps.exif_transpose(pil_img)
        img_clip = ImageClip(np.array(pil_img))
        
        # 2. ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”èª¿æ•´
        base_clip = resize_with_blur(img_clip, target_size=target_resolution)
        
        # 3. ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
        anim_clip = apply_animation(base_clip, preset["animation"], preset["duration"])
        
        # 4. ãƒ†ã‚­ã‚¹ãƒˆåˆæˆ
        font_file = preset.get("font_file", "Arial")
        font_path = DEFAULT_FONT
        
        # Font finding logic
        for ext in [".ttf", ".otf", ".ttc"]:
            candidate = os.path.join(ASSETS_DIR, "fonts", f"{font_file}{ext}")
            if os.path.exists(candidate):
                font_path = candidate
                break
        
        if font_path == DEFAULT_FONT:
             fallback_candidate = os.path.join(ASSETS_DIR, "fonts", "BoldGothic.otf")
             if os.path.exists(fallback_candidate):
                 font_path = fallback_candidate

        final_clip = anim_clip
        if txt:
             t_clip = create_text_clip_pil(txt, font_path, color=preset["text_color"], duration=preset["duration"], canvas_size=target_resolution)
             if t_clip:
                 final_clip = CompositeVideoClip([anim_clip, t_clip], size=target_resolution).set_duration(preset["duration"])
        
        clips.append(final_clip)
        
    # é€£çµ
    final_video = concatenate_videoclips(clips, method="compose")
    
    
    # BGMè¿½åŠ 
    if "bgm_path" in preset and preset["bgm_path"] and os.path.exists(preset["bgm_path"]):
        try:
            audio = AudioFileClip(preset["bgm_path"])
            # Loop check
            if audio.duration < final_video.duration:
                # Loop audio to match video duration
                if audio_loop:
                    audio = audio_loop(audio, duration=final_video.duration)
                else:
                    # Manual loop fallback
                    count = int(final_video.duration / audio.duration) + 1
                    # Note: Concatenating AudioFileClips can be tricky, so we load subclip?
                    # Simply making a new CompositeAudioClip with loops is safer if concatenate is hard
                    # But concatenate_audioclips exists in moviepy.editor
                    from moviepy.editor import concatenate_audioclips
                    audio = concatenate_audioclips([audio] * count)
                    audio = audio.subclip(0, final_video.duration)
            else:
                audio = audio.subclip(0, final_video.duration)
                
            # Audio Fadeout (3sec)
            # Try to use audio_fadeout from moviepy.audio.fx.all
            try:
                from moviepy.audio.fx.all import audio_fadeout
                audio = audio.fx(audio_fadeout, 3)
            except ImportError:
                 # Fallback: manually fadeout if possible, or skip
                 # audio.audio_fadeout exists in some versions?
                 if hasattr(audio, 'audio_fadeout'):
                     audio = audio.audio_fadeout(3)
            except Exception as e:
                print(f"Audio Fadeout failed: {e}")
                pass

            final_video = final_video.set_audio(audio)
        except Exception as e:
            print(f"BGM Error: {e}")
            pass
            
    # Video Fadeout (End 3 sec)
    try:
        final_video = final_video.fx(vfx.fadeout, 3)
    except:
        pass # vfx.fadeout might need color argument? vfx.fadeout(clip, duration)
    
    # 5. é€ã‹ã—
    final_video = add_watermark(final_video, logo_path=logo_path, opacity=0.3)
    
    # æ›¸ãå‡ºã—
    final_video.write_videofile(output_path, fps=30, codec="libx264", audio_codec="aac")
    return output_path
